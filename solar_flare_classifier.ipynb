{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Flare Classifier\n",
    "\n",
    "The goal of this analysis is to write a Support Vector Machine which will classify solar flare type. Our output class will roughly be the \"flare_class\" column of the DataFrame below. For simplicity, I have boiled the flare class to simply be a letter. \"B\" for all B class flares, \"C\", for all C class flares, \"A\" for all A class flares, \"M\" for all M class flares, and \"X\" for all X class flares. In the file `xray_data_wrangling.ipynb`, we have code which one-hot-encodes \"flare_class\" column. These are the columns \"B\", \"C\", \"M\", \"X\", and \"A\". The input features will be the \"xrsb_flux\", the \"background_flux\" and the \"integrated_flux\", all of which will be standardized.\n",
    "\n",
    "Note: To eliminate noise, we will consider only the PEAK x-ray flux data of each solar event. This means that we will consider only the rows of the DataFrame which have a \"status\" of \"EVENT_PEAK\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrayData = pd.read_csv(\"data/xrsSummaryOneHotEncoded.csv\")\n",
    "xrayData.dropna(inplace=True)\n",
    "xrayData[\"flux_standardized\"] = (xrayData['xrsb_flux'] - xrayData['xrsb_flux'].mean()) / xrayData['xrsb_flux'].std()\n",
    "xrayData[\"background_standardized\"] = (xrayData['background_flux'] - xrayData['background_flux'].mean()) / xrayData['background_flux'].std()\n",
    "xrayData[\"integrated_standardized\"] = (xrayData['integrated_flux'] - xrayData['integrated_flux'].mean()) / xrayData['integrated_flux'].std()\n",
    "display(xrayData.head())\n",
    "# Consider only the peak of each solar event\n",
    "xrayData = xrayData[xrayData.status == \"EVENT_PEAK\"]\n",
    "xrayData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Input Features and Output Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, drop all \"A\" class flares. There are only **two**, so if both are includinig in training or if both are included in testing an error will be thrown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrayData = xrayData[xrayData['flare_type'] != \"A\"]\n",
    "\n",
    "split = 0.7\n",
    "trainCount = int(split * len(xrayData))\n",
    "trainIndices = np.random.choice(xrayData.index,trainCount,replace=False)\n",
    "train = xrayData[xrayData.index.isin(trainIndices)]\n",
    "test = xrayData[xrayData.index.isin(trainIndices) == False]\n",
    "# train = xrayData[0:cutoff]\n",
    "# test = xrayData[cutoff:-1]\n",
    "features = ['flux_standardized', 'background_standardized', 'integrated_standardized']\n",
    "# features = ['xrsb_flux', 'background_flux', 'integrated_flux']\n",
    "X = xrayData[features]\n",
    "trainX = train[features]\n",
    "testX = test[features]\n",
    "\n",
    "# classNames = [\"A\",\"B\", \"C\", \"M\", \"X\"]\n",
    "classNames = [\"B\", \"C\", \"M\", \"X\"]\n",
    "classes = ['flare_type']\n",
    "y = xrayData[classes]\n",
    "trainY = train[classes]\n",
    "testY = test[classes]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data with Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(xrayData)\n",
    "subset = xrayData[0:size]\n",
    "step = [i for i in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=subset, x=step, y='xrsb_flux', hue='flare_type', marker=\".\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"XRS-B Flux Over Time with Flare Type\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.show()\n",
    "sns.scatterplot(data=subset, x=step, y='background_flux', hue='flare_type', marker=\".\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.title(\"Background Flux Over Time with Flare Type\")\n",
    "plt.show()\n",
    "sns.scatterplot(data=subset, x=step, y='integrated_flux', hue='flare_type', marker=\".\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Integrated Flux Over Time with Flare Type\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ML Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC(kernel='rbf', class_weight={\"B\": 200, \"C\": 200, \"M\": 5, \"X\": 100})\n",
    "classifier.fit(trainX,trainY.values.reshape(len(trainY),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(testX)\n",
    "test = test.assign(prediction=y_pred)\n",
    "metrics = {\"precision\": 0, \"recall\": 0, \"f-score\": 0, \"support\": 0}\n",
    "p, r, f, s = precision_recall_fscore_support(testY, y_pred, labels=classNames)\n",
    "metrics['precision'] = p\n",
    "metrics[\"recall\"] = r\n",
    "metrics['f-score'] = f\n",
    "metrics['support'] = s\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay.from_estimator(classifier, testX, testY, display_labels=classNames)\n",
    "disp.ax_.set_title(\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Predictions vs. Actual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['correct'] = test['flare_type'] == test['prediction']\n",
    "sns.scatterplot(data=test, x=[i for i in range(len(test))], y=\"xrsb_flux\", hue='correct', marker='.')\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Graph of XRS-B Flux and if the SVM Predicted Correctly\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of false predictions\n",
    "display(len(test[test.correct == False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonteCarloCrossValidation(n, split, data, features, classes, classNames):\n",
    "    clf = svm.SVC(kernel='rbf', class_weight={\"B\": 200, \"C\": 200, \"M\": 5, \"X\": 100})\n",
    "    metrics = {}\n",
    "    for cls in classNames:\n",
    "        metrics[cls] = {\"p\": 0, \"r\": 0, \"f\": 0, \"s\": 0}\n",
    "    for _ in range(n):\n",
    "        trainCount = int(split * len(data))\n",
    "        trainIndices = np.random.choice(data.index,trainCount,replace=False)\n",
    "        train = data[data.index.isin(trainIndices)]\n",
    "        test = data[data.index.isin(trainIndices) == False]\n",
    "        trainX = train[features]\n",
    "        trainY = train[classes]\n",
    "        testX = test[features]\n",
    "        testY = test[classes]\n",
    "\n",
    "        clf.fit(trainX,trainY.values.reshape(len(trainY),))\n",
    "        predY = clf.predict(testX)\n",
    "        p, r, f, s = precision_recall_fscore_support(testY, predY)\n",
    "        for i in range(len(classNames)):\n",
    "            metrics[classNames[i]][\"p\"] += p[i]\n",
    "            metrics[classNames[i]][\"r\"] += r[i]\n",
    "            metrics[classNames[i]][\"f\"] += f[i]\n",
    "            metrics[classNames[i]][\"s\"] += s[i]\n",
    "    for val in metrics.values():\n",
    "        for key in val.keys():\n",
    "            val[key] /= n\n",
    "    return metrics\n",
    "\n",
    "display(\"Average p,r,f,s for each class:\")\n",
    "MonteCarloCrossValidation(10,0.7,xrayData,features,classes,classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, try predicting based on only one feature\n",
    "\n",
    "We use Monte Carlo Cross Validation to see how our model does with only one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"Based on Standardized Flux\")\n",
    "display(MonteCarloCrossValidation(4,0.7,xrayData,[\"flux_standardized\"], classes, classNames))\n",
    "display(\"Based on Standardized Background Flux\")\n",
    "display(MonteCarloCrossValidation(4,0.7,xrayData,[\"background_standardized\"], classes, classNames))\n",
    "display(\"Based on Standardized Integrated Flux\")\n",
    "MonteCarloCrossValidation(4,0.7,xrayData,[\"integrated_standardized\"], classes, classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:**  Model seems to perform *better* with only the standardized XRS-B flux. Let's compare that model with the full model, and with a model excluding the background flux, which seems to perform the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(MonteCarloCrossValidation(10,0.7,xrayData,['flux_standardized'],classes, classNames))\n",
    "display(MonteCarloCrossValidation(10,0.7,xrayData,['flux_standardized','integrated_standardized'],classes, classNames))\n",
    "MonteCarloCrossValidation(10,0.7,xrayData,features,classes, classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs best when only the standardized XRS-B flux is used, so we will simplify our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- DEFINE INPUT AND OUTPUT --\n",
    "features = ['flux_standardized']\n",
    "# features = ['xrsb_flux', 'background_flux', 'integrated_flux']\n",
    "X = xrayData[features]\n",
    "trainX = train[features]\n",
    "testX = test[features]\n",
    "\n",
    "# classNames = [\"A\",\"B\", \"C\", \"M\", \"X\"]\n",
    "classNames = [\"B\", \"C\", \"M\", \"X\"]\n",
    "classes = ['flare_type']\n",
    "y = xrayData[classes]\n",
    "trainY = train[classes]\n",
    "testY = test[classes]\n",
    "\n",
    "# -- DEFINE MODEL --\n",
    "classifier = svm.SVC(kernel='rbf', class_weight={\"B\": 200, \"C\": 200, \"M\": 5, \"X\": 100})\n",
    "classifier.fit(trainX,trainY.values.reshape(len(trainY),))\n",
    "\n",
    "# -- PREDICT --\n",
    "y_pred = classifier.predict(testX)\n",
    "test = test.assign(prediction=y_pred)\n",
    "metrics = {\"precision\": 0, \"recall\": 0, \"f-score\": 0, \"support\": 0}\n",
    "p, r, f, s = precision_recall_fscore_support(testY, y_pred, labels=classNames)\n",
    "metrics['precision'] = p\n",
    "metrics[\"recall\"] = r\n",
    "metrics['f-score'] = f\n",
    "metrics['support'] = s\n",
    "display(metrics)\n",
    "\n",
    "# -- MAKE PLOTS --\n",
    "disp = ConfusionMatrixDisplay.from_estimator(classifier, testX, testY, display_labels=classNames)\n",
    "disp.ax_.set_title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "test['correct'] = test['flare_type'] == test['prediction']\n",
    "sns.scatterplot(data=test, x=[i for i in range(len(test))], y=\"xrsb_flux\", hue='correct', marker='.')\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Graph of XRS-B Flux and if the SVM Predicted Correctly\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "display(ax)\n",
    "sns.scatterplot(data=test, x=[i for i in range(len(test))], y=\"xrsb_flux\", hue='flare_type', marker='.', ax=ax[0])\n",
    "ax[0].set_title(\"XRS-B Flux with Actual Flare Class\")\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_xlabel(\"Point Label\")\n",
    "sns.scatterplot(data=test, x=[i for i in range(len(test))], y=\"xrsb_flux\", hue='prediction', marker='.', ax=ax[1])\n",
    "ax[1].set_title(\"XRS-B Flux with Predicted Flare Class\")\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_xlabel(\"Point Label\")\n",
    "plt.show()\n",
    "\n",
    "# Cross validation\n",
    "display(MonteCarloCrossValidation(20,0.7,xrayData,['flux_standardized'],classes, classNames))\n",
    "\n",
    "# Number of false predictions\n",
    "display(len(test[test.correct == False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "display(ax)\n",
    "sns.scatterplot(data=test, x=[i for i in range(len(test))], y=\"xrsb_flux\", hue='flare_type', marker='.', ax=ax[0])\n",
    "ax[0].set_title(\"XRS-B Flux with Actual Flare Class\")\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_xlabel(\"Point Label\")\n",
    "sns.scatterplot(data=test, x=[i for i in range(len(test))], y=\"xrsb_flux\", hue='prediction', marker='.', ax=ax[1])\n",
    "ax[1].set_title(\"XRS-B Flux with Predicted Flare Class\")\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_xlabel(\"Point Label\")\n",
    "plt.show()\n",
    "\n",
    "len(train) + len(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
